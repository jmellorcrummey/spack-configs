#  CUSTOMIZED for msi3 on gpu.cs
#
#  packages.yaml
#
#  This file specifies the versions and variants for HPCToolkit's
#  dependency packages and serves as a common reference point for how
#  to build them.  It also specifies the paths or modules for system
#  build tools (cmake, python, etc) to avoid rebuilding them.
#
#  Put this file in one of spack's configuration scope directories,
#  normally either <spack-root>/etc/spack, or else in its own,
#  separate directory (and then use 'spack -C dir').
#
#  There are two main sections: (1) hpctoolkit dependency specs,
#  and (2) system build tools: cmake, perl, python, MPI and GCC.
#
#  See also:
#    https://spack.readthedocs.io/en/latest/basic_usage.html#specs-dependencies
#    https://spack.readthedocs.io/en/latest/build_settings.html
#
packages:
  all:
    target: ['x86_64']

  #------------------------------------------------------------
  # 1 -- HPCToolkit Prerequisite Packages
  #------------------------------------------------------------

  # This section contains hpctoolkit's prerequisites, recommended
  # versions and necessary variants.  For most packages, the most
  # recent version will work.
  #
  # Note: the following packages have variants that may need changing
  # for your local system.
  #
  #   1. boost -- avoid 1.68.0, it breaks the build in hpctoolkit.
  #   1.66.0 is good for all dyninst revs.
  #
  #   2. dyninst -- use version 9.3.2 for Blue Gene with the default
  #   gcc 4.4 compilers.  (not recommended)
  #
  #   3. elfutils -- 0.176 doesn't build on Blue Gene, use 0.175.
  #
  #   4. intel-tbb -- add '~tm' for AMD, Xeon Phi (KNL, etc), and very
  #   old Intel systems that don't support transactional memory.
  #
  #   5. libmonitor -- add '+bgq' on Blue Gene/Q.
  #
  #------------------------------------------------------------


  # cuda -- nvidia cuda, now used in master.
  #
  # If there is a pre-built cuda for the system, then it may be better
  # to use that with a 'paths:' or 'modules:' entry.
  #
  # If installing here, then use >= 10.1 and check that the cuda
  # system drivers are installed.
  #
  cuda:
    modules:
      cuda@10.1.243:  cuda/10.1.243
    buildable: False


  # dyninst -- used in hpcstruct for line map info, inline sequences
  # and loop analysis.
  #
  # Need >= 10.1.0 for full cuda CFG support.
  # On Blue Gene, with default gcc 4.4 compilers, use version 9.3.2.
  #
  # +openmp is to support openmp threads in parseapi.
  #
  # dyninst:
  #   version:  [develop]
  #   variants: +openmp build_type=RelWithDebInfo


  #------------------------------------------------------------
  # 2 -- System Build Tools
  #------------------------------------------------------------

  # We require cmake >= 3.4, perl >= 5.x and python 2.7.x or 3.x.
  # There are three ways to satisfy these requirements: a system
  # installed version (eg, /usr), a module or build from scratch.
  #
  # By default, spack will rebuild these, even if your version is
  # perfectly fine.  If you already have an installed version and
  # prefer to use that instead, then uncomment some entry below and
  # edit to fit your system.
  #
  # Note: these three are all build tools.  They are needed to build
  # hpctoolkit, but we don't need them at run time or link with any
  # libraries.  (Not counting hpcsummary which is a python script.)
  #
  #------------------------------------------------------------


  # cmake -- dyninst requires cmake >= 3.4.x.

  # Example for a system install.  This example says that cmake 3.11.0
  # is available at /usr/bin/cmake.  Note: the 'paths:' entry is the
  # parent directory of 'bin', not the bin directory itself (similar
  # to prefix).

  # Example for a module.  This example says that cmake 3.7.2 is
  # available from module 'CMake/3.7.2'.
  cmake:
    modules:
      cmake@3.14.5:  CMake/3.14.5
    buildable: False

  # Example spec to build cmake from scratch.
  # +ownlibs, ~qt and ~openssl are to reduce prerequisites.
  # cmake:
  #   version:  [3.12.4]
  #   variants: +ownlibs ~qt ~openssl

  #------------------------------------------------------------

  # perl -- autotools requires perl >= 5.x which most systems have.

  # Example for system perl.
  perl:
    paths:
      perl@5.16.3:  /usr
    buildable: False

  # Example spec to build perl.
  # perl:
  #   version:  [5.26.2]

  #------------------------------------------------------------

  # python -- spack always requires python >= 2.6 to do anything.
  # On x86, intel-xed requires python 2.7.x or >= 3.4.

  # Example for system python.
  # python:
  #   paths:
  #     python@2.7.5:  /usr
  #   buildable: False

  # Example for python module.
  python:
    modules:
      python@2.7.16:  Python/2.7.16
    buildable: False

  # Example spec to build python.
  # ~dbm, ~tk are to reduce prerequisites.
  # python:
  #   version:  [2.7.15, 3.6.5]
  #   variants: ~dbm ~tk

  #------------------------------------------------------------

  # MPI -- hpctoolkit always supports profiling MPI applications.
  # Adding MPI here is only for building hpcprof-mpi, the MPI version
  # of hpcprof.
  #
  # Normally, you want MPI from a module (mpich, mvapich, openmpi)
  # that was built for the correct interconnect system for the compute
  # nodes.  Also, for hpcprof-mpi, MPI should be built with GNU
  # gcc/g++ and the same version used to build hpctoolkit (to keep the
  # C++ libraries in sync).
  #
  openmpi:
    modules:
      openmpi@3.1.0:  spectrum-mpi/rolling-release
    buildable: False

  #------------------------------------------------------------

  # GCC -- hpctoolkit requires building with GNU gcc/g++.  We require
  # version 5.x or later.
  #
  # Spack handles compilers specially with the compilers.yaml file.
  # This example is only for building a more recent compiler.
  #
  # Note: spack will select the first version that is compatible with
  # the rest of the spec and command line.  So, put the version you
  # want to build first.  4.8.4 is really only for Blue Gene.

  # gcc:
  #   version:  [7.4.0, 6.4.0, 5.5.0, 4.8.4]

